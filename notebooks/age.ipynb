{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Prediction Sandbox Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "version = '50'\n",
    "project_root = os.path.abspath('..')\n",
    "load_dir = os.path.join(project_root, 'data/input/unsegmented')\n",
    "segmentations_dir = os.path.join(project_root, f'data/output/segmentations/{version}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load segmentations and labels\n",
    "labels = []\n",
    "images = []\n",
    "for index, file_name in enumerate(sorted(glob.glob(os.path.join(load_dir, '*.nii.gz')))):\n",
    "    segmentaiton_path = os.path.join(segmentations_dir, f'{index}.nii.gz')\n",
    "    img = sitk.ReadImage(segmentaiton_path)\n",
    "    images.append(sitk.GetArrayFromImage(img))\n",
    "    \n",
    "    age_str = file_name.split('_')[-1].split('.')[:-2]\n",
    "    age = int(age_str[0]) + (len(age_str)-1)*int(age_str[-1])/10.\n",
    "    labels.append(age)\n",
    "    #print(images[-1].shape, age_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0][99], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('An example of generated segmentation.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(images)\n",
    "n_features = 3\n",
    "features = np.zeros((n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy featere set and labels\n",
    "for i, img in enumerate(images):\n",
    "    features[i, 0] = (img == 1).sum()\n",
    "    features[i, 1] = (img == 2).sum()\n",
    "    features[i, 2] = (img == 3).sum()\n",
    "    \n",
    "features = features / features.sum(axis=-1, keepdims=True)\n",
    "labels = np.array(labels).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test part\n",
    "train_val_features, test_features, train_val_labels, test_labels = train_test_split(features, labels, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for grid search\n",
    "parameters = {'poly__degree':[2,3,4,5,6,7,8, 9, 10,11,12], 'ridge__alpha': np.logspace(-6, 6, 13),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline of the model\n",
    "model = Pipeline(steps = [('poly', PolynomialFeatures()),\n",
    "                        ('ridge', Ridge(fit_intercept=False))])\n",
    "\n",
    "#model = Pipeline(steps = [('poly', PolynomialFeatures()),\n",
    "#                        ('lasso', Lasso(fit_intercept=False))])\n",
    "\n",
    "#model = Pipeline(steps = [('poly', PolynomialFeatures()),\n",
    "#                        ('e-net', ElasticNet(fit_intercept=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gridsearch using 5-fold crossvalidation\n",
    "clf = GridSearchCV(model, parameters, )\n",
    "clf.fit(train_val_features, train_val_labels[:, 0])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best results according to the grid search:')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the best model to training part\n",
    "pred = clf.predict(train_val_features)\n",
    "mae = np.mean(np.abs(pred - train_val_labels[:,0]))\n",
    "std = np.std(np.abs(pred - train_val_labels[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Prediction:{pred}\\nLabels: {train_val_labels[:,0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAE: {mae}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the best model to training part\n",
    "pred_test = clf.predict(test_features)\n",
    "mae_test = np.mean(np.abs(pred_test - test_labels[:,0]))\n",
    "std_test = np.std(np.abs(pred_test - test_labels[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAE: {mae_test}, std: {std_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network with couple of linear layes for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Structure\n",
    "\n",
    "dropout_prob = .2\n",
    "in_channels = 3\n",
    "mid_channels = 8\n",
    "out_channels = 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_channels, mid_channels),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(dropout_prob),\n",
    "    torch.nn.Linear(mid_channels, 2 * mid_channels),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(dropout_prob),\n",
    "    torch.nn.Linear(2 * mid_channels, mid_channels),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(dropout_prob),\n",
    "    torch.nn.Linear(mid_channels, out_channels)\n",
    ")\n",
    "\n",
    "# define your optimizer and loss function\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# convert your training arrays to tensors of the correct type\n",
    "\n",
    "X = torch.from_numpy(train_val_features).float()\n",
    "y = torch.from_numpy(train_val_labels).float()\n",
    "\n",
    "num_epochs = 4000  # number of runs through the dataset to train for\n",
    "# batch size equals to the size of dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "losses = []\n",
    "for epoch in range(1, 1 + num_epochs):\n",
    "    model.train()\n",
    "    optimiser.zero_grad()\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, y)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test data to tensors and test your network against the test ground truth data\n",
    "\n",
    "X_test = torch.from_numpy(test_features).float()\n",
    "y_test = torch.from_numpy(test_labels).float()\n",
    "\n",
    "model.train() # To keep Dropout active and produce output for ensemble\n",
    "\n",
    "pred = np.zeros((4,1))\n",
    "# Produce ensemble output\n",
    "for i in range(10):\n",
    "    pred += model(X_test).detach().numpy() \n",
    "pred /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Patient | Prediction | Target')\n",
    "for i in range(len(y_test)):\n",
    "    print(f'  {i}     |   {pred.squeeze()[i]:.2f}    | {y_test.squeeze()[i]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('MSE convergence')\n",
    "plt.xlabel('Iteration')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}